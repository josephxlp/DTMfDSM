{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Generate ROI tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join, basename\n",
    "from os import makedirs,cpu_count\n",
    "from glob import glob\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdir = \"/media/ljp238/12TBWolf/ARCHIEVE/OUT/TONLESAP/\"\n",
    "lidar_dpath = join(wdir, 'LiDAR')\n",
    "tiles_dpath = join(wdir, 'TILES')\n",
    "\n",
    "ds_dpath = \"/media/ljp238/12TBWolf/ARCHIEVE/OUT/TILES12B/N13E103/\"\n",
    "vrt_files = ds_files = glob(f'{ds_dpath}/*.tif'); print(len(ds_files))\n",
    "\n",
    "cpus = int(cpu_count() - 3)\n",
    "basefiles = lidar_files = glob(f'{lidar_dpath}/*.tif')\n",
    "lidar_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio\n",
    "from rasterio.features import shapes\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import shape\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "\n",
    "\n",
    "\n",
    "def gdal_polygonize(tif_path, gpkg_path):\n",
    "    cmd = f'gdal_polygonize.py {tif_path} -b 1 -f \"GPKG\" {gpkg_path}'# OUTPUT DN'\n",
    "    os.system(cmd)\n",
    "\n",
    "def dissolve_features(input_gpkg,output_gpkg):\n",
    "    #input_layer, \n",
    "    \"\"\"\n",
    "    Dissolve all features in a GeoPackage layer into a single geometry.\n",
    "\n",
    "    :param input_gpkg: Path to the input GeoPackage file.\n",
    "    :param input_layer: Name of the layer to dissolve.\n",
    "    :param output_gpkg: Path to the output GeoPackage file with dissolved features.\n",
    "    \"\"\"\n",
    "    # Load the layer from the GeoPackage\n",
    "    gdf = gpd.read_file(input_gpkg)#, layer=input_layer)\n",
    "    \n",
    "    # Dissolve all features into a single geometry\n",
    "    dissolved = gdf.dissolve()\n",
    "    \n",
    "    # Save the dissolved geometry to a new GeoPackage\n",
    "    dissolved.to_file(output_gpkg, driver='GPKG') #layer='dissolved',\n",
    "    print(f\"Dissolved features saved to {output_gpkg}\")\n",
    "\n",
    "def buffer_features(input_gpkg,output_gpkg, buffer_distance):\n",
    "    \"\"\"\n",
    "    Apply a buffer to the dissolved features in a GeoPackage layer.\n",
    "\n",
    "    :param input_gpkg: Path to the input GeoPackage file with dissolved features.\n",
    "    :param input_layer: Name of the layer to buffer.\n",
    "    :param output_gpkg: Path to the output GeoPackage file with buffered features.\n",
    "    :param buffer_distance: Distance for the buffer operation.\n",
    "    \"\"\"\n",
    "    # Load the dissolved layer from the GeoPackage\n",
    "    gdf = gpd.read_file(input_gpkg)#, layer=input_layer)\n",
    "    \n",
    "    # Apply the buffer operation\n",
    "    buffered = gdf.buffer(buffer_distance)\n",
    "    \n",
    "    # Create a new GeoDataFrame to store the buffered geometry\n",
    "    buffered_gdf = gpd.GeoDataFrame(geometry=buffered, crs=gdf.crs)\n",
    "    \n",
    "    # Save the buffered geometry to a new GeoPackage\n",
    "    buffered_gdf.to_file(output_gpkg,driver='GPKG')# layer='buffered', \n",
    "    print(f\"Buffered features saved to {output_gpkg}\")\n",
    "\n",
    "def save_to_gpkg(gdf, output_path):\n",
    "    gdf.to_file(output_path, driver='GPKG')\n",
    "\n",
    "def raster2vectorcutline(raster_path, gpkg_path):\n",
    "    # Convert raster to polygons\n",
    "\n",
    "    gpkg_path_int = gpkg_path.replace('.gpkg', '_P.gpkg')\n",
    "    fb = gpkg_path_int.replace('.gpkg','_B.gpkg')\n",
    "    gdal_polygonize(raster_path, gpkg_path_int)\n",
    "    buffer_features(gpkg_path_int, fb, 0)\n",
    "    dissolve_features(fb,gpkg_path)\n",
    "    os.remove(gpkg_path_int)\n",
    "    os.remove(fb)\n",
    " \n",
    "    print(\"Process completed. Output saved to:\", gpkg_path)\n",
    "\n",
    "\n",
    "for j,fi in enumerate(basefiles):\n",
    "    fo = fi.replace('.tif', '.gpkg')\n",
    "    print(fi,'\\n',fo)\n",
    "    #raster2vectorcutline(fi,fo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "import fiona\n",
    "import os\n",
    "\n",
    "def clip_cultilinex(vpath,rpath, fopath):\n",
    "    cmd = f'gdalwarp -cutline {vpath} -crop_to_cutline -dstalpha {rpath} {fopath}'\n",
    "    os.system(cmd)\n",
    "\n",
    "def clip_cultiline(vpath, rpath, fopath):\n",
    "  # Open the vector file\n",
    "  with fiona.open(vpath, \"r\") as shapefile:\n",
    "      # Extract the geometry from the vector file\n",
    "      shapes = [feature[\"geometry\"] for feature in shapefile]\n",
    "\n",
    "  # Open the raster file\n",
    "  with rasterio.open(rpath) as src:\n",
    "      # Clip the raster with the geometry\n",
    "      out_image, out_transform = mask(src, shapes, crop=True)\n",
    "      out_meta = src.meta.copy()\n",
    "\n",
    "      # Update the metadata to reflect the new dimensions\n",
    "      out_meta.update({\n",
    "          \"driver\": \"GTiff\",\n",
    "          \"height\": out_image.shape[1],\n",
    "          \"width\": out_image.shape[2],\n",
    "          \"transform\": out_transform\n",
    "      })\n",
    "\n",
    "      # Write the clipped raster to a new file\n",
    "      with rasterio.open(fopath, \"w\", **out_meta) as dest:\n",
    "          dest.write(out_image)\n",
    "\n",
    "\n",
    "\n",
    "def get_out_params(tiles_dpath,bfile,src_dataset):\n",
    "    dname = basename(bfile).replace('.gpkg','').split('_')[-1]\n",
    "    dst_dpath = join(tiles_dpath,dname)\n",
    "    makedirs(dst_dpath, exist_ok=True)\n",
    "    dst_dataset = join(dst_dpath,basename(src_dataset))\n",
    "    return dst_dataset\n",
    "\n",
    "\n",
    "gpkg_files = glob(f'{lidar_dpath}/*.gpkg')\n",
    "gpkg_files,lidar_dpath\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ti = time.perf_counter()\n",
    "    with ProcessPoolExecutor(cpus) as PPE:\n",
    "        for i,vrt in enumerate(vrt_files):\n",
    "            src_dataset = vrt\n",
    "            #print(vrt)\n",
    "            for j,bfile in enumerate(gpkg_files):\n",
    "                dst_dataset = get_out_params(tiles_dpath,bfile,src_dataset)\n",
    "                #clip_cultiline(src_dataset,bfile,dst_dataset)\n",
    "\n",
    "               \n",
    "                # PPE.submit(\n",
    "                #    clip_cultilinex,bfile,src_dataset,dst_dataset\n",
    "                # )\n",
    " \n",
    "               \n",
    "    tf = time.perf_counter() - ti\n",
    "    print(f'run.time : {tf/60}  min(s)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Generate patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import rasterio as rio\n",
    "from rasterio import windows\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from glob import glob\n",
    "\n",
    "def get_tiles(ds, tile_width, tile_height, overlap):\n",
    "  nols, nrows = ds.meta['width'], ds.meta['height']\n",
    "  xstep = tile_width - overlap\n",
    "  ystep = tile_height - overlap\n",
    "  for x in range(0, nols, xstep):\n",
    "      if x + tile_width > nols:\n",
    "          x = nols - tile_width\n",
    "      for y in range(0, nrows, ystep):\n",
    "          if y + tile_height > nrows:\n",
    "              y = nrows - tile_height\n",
    "          window = windows.Window(x, y, tile_width, tile_height)\n",
    "          transform = windows.transform(window, ds.transform)\n",
    "          yield window, transform\n",
    "\n",
    "def process_tile(args):\n",
    "  window, transform, src_meta, in_path, out_path, output_filename = args\n",
    "  metadata = src_meta.copy()\n",
    "  metadata['transform'] = transform\n",
    "  metadata['width'], metadata['height'] = window.width, window.height\n",
    "  out_filepath = os.path.join(out_path, output_filename.format(window.col_off, window.row_off))\n",
    "  \n",
    "  with rio.open(in_path) as src:\n",
    "      with rio.open(out_filepath, 'w', **metadata) as dst:\n",
    "          dst.write(src.read(window=window))\n",
    "\n",
    "def calculate_offset(width, height, tile_width, tile_height, stride_x, stride_y):\n",
    "  X = [x for x in range(0, width, stride_x)]\n",
    "  Y = [y for y in range(0, height, stride_y)]\n",
    "  offsets = list(itertools.product(X, Y))\n",
    "  return offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TSAP1', 'TSAP2']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psize = 64\n",
    "WDIR = \"/media/ljp238/12TBWolf/ARCHIEVE/OUT/TONLESAP/TILES/\"\n",
    "tile_width = psize\n",
    "tile_height = psize\n",
    "overlap = 0\n",
    "output_filename = 'tile_{}_{}.tif'\n",
    "tilenames = os.listdir(WDIR)\n",
    "tilenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stile = \"N13E103\"\n",
    "for tilename in tilenames:\n",
    "    tif_dpath = os.path.join(WDIR, tilename)\n",
    "    patch_dpath = os.path.join(tif_dpath, f'P{psize}')\n",
    "    os.makedirs(patch_dpath, exist_ok=True)\n",
    "    tif_files = glob(f'{tif_dpath}/*.tif')\n",
    "    for in_path in tif_files:\n",
    "        out_path = os.path.join(patch_dpath, os.path.splitext(os.path.basename(in_path))[0])\n",
    "        out_path = out_path.replace(f'{Stile}_','')\n",
    "        print(out_path)\n",
    "        os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "        with rio.open(in_path) as src:\n",
    "            src_meta = src.meta.copy()\n",
    "            width, height = src_meta['width'], src_meta['height']\n",
    "            stride_x = tile_width - overlap\n",
    "            stride_y = tile_height - overlap\n",
    "            offsets = calculate_offset(width, height, tile_width, tile_height, stride_x, stride_y)\n",
    "            tiles = [(windows.Window(x, y, tile_width, tile_height), windows.transform(windows.Window(x, y, tile_width, tile_height), src.transform)) for x, y in offsets]\n",
    "\n",
    "        args = [(window, transform, src_meta, in_path, out_path, output_filename) for window, transform in tiles]\n",
    "\n",
    "        with Pool(processes=cpu_count()) as pool:\n",
    "            pool.map(process_tile, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Generate df paths with nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pgeoml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
